# 100DaysOfML
This repository is part of 100 days of ML. I am taking up the challenge to to Learn Machine Learning at least an hour everyday!!
This one hour can be studying or coding the machine learning realted topics.

Challenge is starting from June 06 2018.

### Day 0: July 05 2018: 

### Setup:
I have setup all the thing needed to complete the challenge. 

Tools and Technologies I am planning to use : 

* Anconda, Python, Juypter Notebook
* Libraries : Sci-Kit Learn, Tensorflow
* Data visualization: D3.js , Matplotlib

I have installed all the libraries and IDE needed for to take this challenge.


### Day 1: July 06 2018: 

### Classification :
 Today I want to work on MNIST dataset. This dataset is a set of 70000 sall images of digits handwritten by high school and employees of the US Census Board. 

Today I did :
* Importing Dataset
* Visualizing the Data
* Splitting Training and Testing 
* Training a Binary Classifier

Classification on MNIST dataset can found [here](https://github.com/rohith28/Classification)

### Day 2 : July 07 2018

### Classification :
In conituation to the above classification:

* Performance Measure 
* Confusion Matrix
* Precision and Recall
* Precision/Recall tradeoff
* ROC Curve


Classification on MNIST dataset can found [here](https://github.com/rohith28/Classification)

### Day 3 : July 08 2018
### Classification

* In past two days I learned 
  * how to train binary classifier
  * choosing metrics for the task
  * Evaluating the classifiers using Cross validation
  * Selecting Precision/ Recall tradeoff
  * Compare models using ROC curves and ROC AUC scores

Today I want to work on :
* Multiclass classification
* Error Analysis
* Multilabel Classification
* Multioutput Classification

Classification on MNIST dataset can found [here](https://github.com/rohith28/Classification)


### Day 4 : July 09 2018
### Linear Regression using Normal Equation


Today I am going to study and implement Linear Regression.

Linear Regression can be implemented by Normal Equation and Gradient Descent.

I am imlpementing with Normal Equation today. You can find the code [here](https://github.com/rohith28/Training-Models/blob/master/Linear%20Regression.ipynb)


### Day 5 : July 10 2018
### Life Statifaction using Linear Regression

Today I am going to work on how Life satifaction and GDP per capita realted.

Applying Linear Regrssion and KNN on two datasets.

Better Life Index data from the OECD's website : https://goo.gl/0Eht9W
GDP percapita from IMF's website : https://goo.gl/j1MSKe

Code can be found [here](https://github.com/rohith28/Training-Models/blob/master/Life_Statisfaction/Life%20Satisfaction.ipynb)


### Day 6 : July 11 2018
### Linear Regression using Gradient Descent

Today I am going to learn
* Different types and theoritical knowlegde of Gradient Descent
* Batch Gradient Descent 
* Implementation of algorithm (Batch Gradient Descent) with out using ML library

Code for impplementation of Linear algorithm using Gradient Descent can be found [here](https://github.com/rohith28/Training-Models/blob/master/Gradient%20Descent.ipynb)


### Day 7 : July 12 2018

Topics to be covered  :
* Stochastic Gradient Descent
* Implementation of algorithm (stochastic Gradient Descent) witout using Scikit-Learn
* Mini-Batch Gradient Descent
* Implementation of algorithm (Mini-batch GD) without using Scikit-learn
* Comparison between Batch, Stochastic and Mini-bacth GD.

Code for impplementation of Linear algorithm using Gradient Descent can be found [here](https://github.com/rohith28/Training-Models/blob/master/Gradient%20Descent.ipynb)


### Day 8 : July 13 2018

Topics :

* Polynomial Regression
* Learning Curves
* Regularized Linear Models
     * Ridge Regression
     * Lasso Regression
     
Code can be found [here](https://github.com/rohith28/Training-Models/blob/master/Polynomial%20Regression.ipynb)

### Day 9 : July 14 2018

I studied and implemented Linear Regression using both Normal equation and Gradient Descent. And also I studied importance of regularization term and Regulariszed Linear models. 

Today I am going to work on following topics:

* Logistic Regression
    * Training and Cost Functions
    * Decision Boundaries
    * Softmax Regression

### Day 10 and Day 11 : July 15, July 16 2018

I am going to work on _Titanic : Machine Learning from Disaster_ which is a _Kaggle Competition._

Dataset can be found [here](https://www.kaggle.com/c/titanic/data).

* Data Analysis
* Data Visualization
* Data Wrangling
* Predicting using Logistic Regression

Notebook for this Kaggle Competition can be found [here](https://github.com/rohith28/Titanic_Kaggle)

### Day 12 : July 17 2018

Today taking a break from the machine learning algorithms and I want to work on Visualization using matplotlib and basemap.

I want to visualize the U.S. Pollution dataset which you can find in [Kaggle](https://www.kaggle.com/sogun3/uspollution)

I did some scatter plots and animations. You can find my code in this [notebook](https://github.com/rohith28/Visualization_US_Pollution_dataset/blob/master/visualization.ipynb)

### Day 13 : July 18 2018

Today strated to learn about Support Vector Machines. I want to imlement Linear SVM Classification and learn the differences between Soft margin Classification and Hard margin Classification.

My notes and classifier can be found [here](https://github.com/rohith28/Training-Models/blob/master/SupportVectorMachines.ipynb)

### Day 14: July 19 2018

I studied about Non Linear SVM Classificaiton and SVM Regressor and how they work.

### Day 15: July 20 2018

Todays topic is Decision tree and its visulization.how to make predition using Decision Tree.


##   : July 27 2018

Started working Kaggle competition : [New York Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration)
Created machine learning model using XGBoost.
